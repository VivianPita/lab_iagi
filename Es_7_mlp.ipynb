{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+wVwaGULdS6qNy+bUEMKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivianPita/lab_iagi/blob/main/Es_7_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Field test del MultiLayer Perceptron\n",
        "\n",
        "Questo è il testo dell'esercitazione che dovrete completare per questa settimana. Non sarà guidato passo passo, ma\n",
        "dovrete usare quello che avete imparato negli altri jupyter notebooks per addestrare dei modelli e cross-validarli,\n",
        "al massimo delle vostre capacità.\n",
        "I tre esercizi da svolgere sono:\n",
        "\n",
        "1. addestrare un MLP su [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Potete utilizzare il codice\n",
        " del precedente notebook, ma vi consiglio di riscriverlo in maniera più ordinata. In questo caso, fate prima\n",
        " un'analisi dei dati per capire con cosa avete a che fare.\n",
        "2. addestrare un MLP su [YearPredictionMSD](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD): l'idea di\n",
        "      questo esercizio è quella di utilizzare una rete neurale per migliorare le performance rispetto alla soluzione\n",
        "      che avete già implementato con la logistic regression nell'[esercitazione 6](https://github.com/Sapienza-AI-Lab/esercitazione6-22-23). In questo caso l'aspetto che ci\n",
        "      preme esplorare è l'efficacia del MLP nell'imparare una rappresentazione (i.e. delle features) migliore per la\n",
        "      classifcazione, o la regressione. Questo esercizion non è banale e sono interessato a vedere come sfrutterete\n",
        "      le reti neurali per migliorare le prestazioni. Se non avete fatto l'EDA durante la scorsa esercitazione, questo è il momento di farla.\n",
        "3. addestrare un MLP su CIFAR-10: riprenderemo questo dataset anche con le reti convoluzionali, ma iniziamo a\n",
        "      farci un'idea delle sue caratterisitche addestrando im modello migliore possibile utilizzando un MLP. La sfida\n",
        "      in questo caso sarà la dimensionalità dell'input, e quindi delle connessioni del MLP.\n",
        "\n",
        "\n",
        "In tutti i casi tenete conto di questi aspetti:\n",
        "* Non siete costretti ad usare i notebook. Personalmente non li amo, ma sono adatti a presentare il codice per la\n",
        "    didattica. Per lavorare con progetti di una certa complessità è spesso meglio passare ad un normale progetto\n",
        "    python. Ovviamente se non avete una GPU nel vostro portatile/desktop, l'unica soluzione è colab.\n",
        "* Utilizzate tensorboard o weight and biases per la visualizzazione e per fare il debug del vostro modello. Non provate le cose a caso.\n"
      ],
      "metadata": {
        "id": "rzdxIdGeSyQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LIBRERIE + MODEL SET UP\n"
      ],
      "metadata": {
        "id": "PNXW6kq9TVEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sRuvGo0ESorg"
      },
      "outputs": [],
      "source": [
        "#importo le varie librerie\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    super(MLP,self).__init__()\n",
        "    self.fc1=nn.Linear(input_size,hidden_size)\n",
        "    self.fc2=nn.Linear(hidden_size,output_size)\n",
        "  def forward(self,x):\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ce-w7_u9j--P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, optimizer, loss_fn, epochs, train_loader, validation_loader):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            data = data.view(data.shape[0], -1)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = loss_fn(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader),\n",
        "                    loss.item()\n",
        "                ))\n",
        "        train_losses.append(total_loss / len(train_loader))\n",
        "\n",
        "        total_loss = 0\n",
        "        for data, target in validation_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            data = data.view(data.shape[0], -1)\n",
        "            output = model(data) #validation using the model with the updated weights and biases from the training\n",
        "            loss = loss_fn(output, target)\n",
        "            total_loss += loss.item()\n",
        "        validation_losses.append(total_loss / len(validation_loader))\n",
        "\n",
        "    return train_losses, validation_losses"
      ],
      "metadata": {
        "id": "bfgoOpKglSu5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, loader, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad(): #no need to calculate the gradients when testing\n",
        "        for data, target in loader: #loader is the test_loader\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            data = data.view(data.shape[0], -1)\n",
        "            output = model(data) #do not calculate the gradients because of the line with torch.no_grad()\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True) #keep dim for example is [[1], [2]] instead of [1, 2]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() #sum up the correct predictions\n",
        "    test_loss /= len(loader.dataset)\n",
        "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss,\n",
        "        correct,\n",
        "        len(loader.dataset),\n",
        "        100. * correct / len(loader.dataset)\n",
        "    ))"
      ],
      "metadata": {
        "id": "x7jQISE2mXzf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Zlu2i-16mcYX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FASHIONMNIST"
      ],
      "metadata": {
        "id": "1o3_tsnxme8U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfSEOjuimmKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pay26MxCmjNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}